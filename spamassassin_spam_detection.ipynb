{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7568520",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7ee2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682812b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with encoding='latin-1' to avoid UnicodeDecodeError\n",
    "data = pd.read_csv('spam_messages.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e648b4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the top 5 rows\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273cac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of the dataset (number of rows, number of columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9809a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0116ff",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b668ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop irrelevant columns\n",
    "data = data[['v1', 'v2']]  # v1 = label, v2 = message\n",
    "\n",
    "# Rename columns for clarity\n",
    "data.columns = ['Label', 'Message']\n",
    "\n",
    "# Check and remove null values\n",
    "data.isnull().sum()\n",
    "data = data.dropna()\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc98177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1c81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dab68f",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e437d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     4516\n",
       "spam     653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count labels\n",
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "665d6f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43bed9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK tokenizer working: 1 sentences detected\n",
      "New columns: ['Label', 'Message', 'num_characters', 'num_words', 'num_sentences']\n",
      "Sample of new features:\n",
      "   num_characters  num_words  num_sentences\n",
      "0             111         20              2\n",
      "1              29          6              2\n",
      "2             155         28              2\n",
      "3              49         11              1\n",
      "4              61         13              1\n",
      "5             148         32              4\n",
      "6              77         16              2\n",
      "7             160         26              2\n",
      "8             158         26              5\n",
      "9             154         29              3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.download('punkt_tab')\n",
    "except:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    from nltk.tokenize import sent_tokenize\n",
    "    test = sent_tokenize(\"This is test message\")\n",
    "    print(f\"NLTK tokenizer working: {len(test)} sentences detected\")\n",
    "    use_nltk = True\n",
    "except Exception as e:\n",
    "    print(f\"NLTK failed: {e}\")\n",
    "    use_nltk = False\n",
    "\n",
    "# Character count\n",
    "data['num_characters'] = data['Message'].apply(len)\n",
    "\n",
    "# Word count  \n",
    "data['num_words'] = data['Message'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Sentence count\n",
    "if use_nltk:\n",
    "    data['num_sentences'] = data['Message'].apply(lambda x: len(sent_tokenize(str(x))))\n",
    "else:\n",
    "    import re\n",
    "    def count_sentences(text):\n",
    "        # Split on sentence endings and count non-empty results\n",
    "        sentences = re.split(r'[.!?]+', str(text))\n",
    "        return len([s for s in sentences if s.strip()])\n",
    "    \n",
    "    data['num_sentences'] = data['Message'].apply(count_sentences)\n",
    "\n",
    "print(f\"New columns: {list(data.columns)}\")\n",
    "print(\"Sample of new features:\")\n",
    "print(data[['num_characters', 'num_words', 'num_sentences']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d441828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  num_characters  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...             111   \n",
       "1   ham                      Ok lar... Joking wif u oni...              29   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
       "3   ham  U dun say so early hor... U c already then say...              49   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...              61   \n",
       "\n",
       "   num_words  num_sentences  \n",
       "0         20              2  \n",
       "1          6              2  \n",
       "2         28              2  \n",
       "3         11              1  \n",
       "4         13              1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73753d27",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a726c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (5169, 6)\n",
      "Columns: ['Label', 'Message', 'num_characters', 'num_words', 'num_sentences', 'transformed_message']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Download with force=True to ensure fresh downloads\n",
    "downloads = [\n",
    "    ('stopwords', 'Stopwords corpus'),\n",
    "    ('punkt', 'Punkt tokenizer'),\n",
    "    ('punkt_tab', 'Punkt tokenizer (new version)'),\n",
    "]\n",
    "\n",
    "for package, description in downloads:\n",
    "    try:\n",
    "        nltk.download(package, force=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {package}: {e}\")\n",
    "\n",
    "# Now import the required modules\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    \n",
    "    # Test that stopwords work\n",
    "    english_stopwords = stopwords.words('english')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Import failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Initialize the stemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def transform_text(text):\n",
    "    text = text.lower()                            # convert to lowercase\n",
    "    text = nltk.word_tokenize(text)                # Split the text  into words\n",
    "    text = [word for word in text if word.isalnum()]  # Remove special characters\n",
    "    text = [word for word in text if word not in english_stopwords and word not in string.punctuation]  # Remove stopwords and punctuation\n",
    "    text = [ps.stem(word) for word in text]        # Apply Stemming\n",
    "    return \" \".join(text)         \n",
    "\n",
    "data['transformed_message'] = data['Message'].apply(transform_text)\n",
    "\n",
    "# Check dataset\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e532934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>transformed_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                            Message  num_characters  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...             111   \n",
       "1   ham                      Ok lar... Joking wif u oni...              29   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...             155   \n",
       "3   ham  U dun say so early hor... U c already then say...              49   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...              61   \n",
       "\n",
       "   num_words  num_sentences                                transformed_message  \n",
       "0         20              2  go jurong point crazi avail bugi n great world...  \n",
       "1          6              2                              ok lar joke wif u oni  \n",
       "2         28              2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3         11              1                u dun say earli hor u c alreadi say  \n",
       "4         13              1               nah think goe usf live around though  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dca8c358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import two text vectorization tools from scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Count Vectorizer: Simple bag-of-words approach\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# fit_transform() builds a vocabulary of all words in the corpus and transforms each message into a numeric array based on word counts\n",
    "X_bow = cv.fit_transform(data['transformed_message']).toarray()\n",
    "\n",
    "\n",
    "# Create a TfidfVectorizer instance (Better for weighting important words) with max_features=3000 to limit the number of unique words to 3000\n",
    "tfidf = TfidfVectorizer(max_features=3000)\n",
    "\n",
    "# Apply TF-IDF on the same preprocessed text to give higher weight to important, rare words and lower weight to frequent ones\n",
    "X = tfidf.fit_transform(data['transformed_message']).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e653d0c",
   "metadata": {},
   "source": [
    "# Best Model Selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
